# python聚类分析-摩拜单车用户分群

前面讲到的线性回归和逻辑回归的数据样本都是确定了Y值的，通俗一点来讲就是:**从给定的训练数据集中学习出一个函数（[模型参数](https://www.zhihu.com/search?q=%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A106561665%7D)），当新的数据到来时，可以根据这个函数预测结果。**

所以线性回归和逻辑回归都是监督学习

今天要讲的[聚类分析](https://www.zhihu.com/search?q=%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A106561665%7D)是无监督学习，无监督学习就是：**输入数据没有被标记，也没有确定的结果。样本数据类别未知，需要根据样本间的相似性对样本集进行分类（聚类，clustering）试图使类内差距最小化，类间差距最大化。**

具体区别可以参考：

[CSDN-专业IT技术社区-登录**blog.csdn.net/u010947534/article/details/82025794**](https://link.zhihu.com/?target=https%3A//blog.csdn.net/u010947534/article/details/82025794)

---

下面分享一个聚类分析模型对[摩拜单车](https://www.zhihu.com/search?q=%E6%91%A9%E6%8B%9C%E5%8D%95%E8%BD%A6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A106561665%7D)用户进行分类的案例

数据链接：

[https://pan.baidu.com/s/1WGJY-MEE13yj4MEpGJAryA**pan.baidu.com/s/1WGJY-MEE13yj4MEpGJAryA**](https://link.zhihu.com/?target=https%3A//pan.baidu.com/s/1WGJY-MEE13yj4MEpGJAryA)

提取码:9jpj

**问题：基于所给数据，利用Python数据进行聚类分析，对摩拜单车的使用者进行分群。**

![](https://pic4.zhimg.com/80/v2-1c2fbd7cf891eea80d2000a407d3538f_1440w.jpg)**Step1.数据预处理**

![](https://pic1.zhimg.com/80/v2-07bbf322a63b7d8be9fbf0b3580c16c4_1440w.jpg)1.删除对业务分析没有实际作用的变量

2.删除空值

3.删除与实际情况不符的异常值，例如过大的年龄

4.将[类别型变量](https://www.zhihu.com/search?q=%E7%B1%BB%E5%88%AB%E5%9E%8B%E5%8F%98%E9%87%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A106561665%7D)转换成数字型变量

![](https://pic3.zhimg.com/80/v2-71b9e4b7e8339c3fb2c83ca30611fc6e_1440w.jpg)1.unique()查询有多少个起始站，发现有许多个，如果是少数说不定有业务意义，如果有很多个的话就删除，另外‘Unnamed:0’(可能是骑行旅程编号），用户ID,自行车编码，起始站名和和编码，终点站名和编码都是对业务分析没有实际作用的变量，可以删除。

![](https://pic2.zhimg.com/80/v2-8b9136af9295b0c7332df2a022bd8ed1_1440w.jpg)2.

![](https://pic1.zhimg.com/80/v2-3bdfda2821b17f53d53af8e0a25206d8_1440w.jpg)空值占比很小，可以删除，得到没有空值的数据

![](https://pic1.zhimg.com/80/v2-0fe4ecef0ccccd53f9f8efdca36599e4_1440w.jpg)先用describe对数据进行一个描述统计，因为describe()只能针对数据型变量进行统计，所以这边只会显示birthyear，需要改变其他变量的数据类型。

![](https://pic4.zhimg.com/80/v2-2f049d055a143151c023caad87bc9593_1440w.png)tripduration中1,090，这种类型没法直接转变成数据型变量，我们可以先用[replace函数](https://www.zhihu.com/search?q=replace%E5%87%BD%E6%95%B0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A106561665%7D)把“，”去掉然后再转。

![](https://pic3.zhimg.com/80/v2-d46cb854834b23f6784650af4bb69b22_1440w.jpg)![](https://pic2.zhimg.com/80/v2-2de45361a8c51d55dc53422e49447d1d_1440w.jpg)age可以直接转，usertype,gender都是类别型变量。

![](https://pic2.zhimg.com/80/v2-b7233ca9138872451d5e61074a4bbd8d_1440w.jpg)tripduration单位是米，一般最大值比75%位数大三四倍就是异常值，我们这里可以看下超过5000的记录数，年龄可以降到80.

![](https://pic2.zhimg.com/80/v2-0253aee0818d3d47108928732fd91cd5_1440w.jpg)![](https://pic2.zhimg.com/80/v2-1a41b7c25a0f425d871066a93a1b6bb1_1440w.jpg)发现骑行距离超过5000米的记录只有25个，可以删除。

![](https://pic4.zhimg.com/80/v2-3994c97e084832c70fe1053ed384a68b_1440w.jpg)将起始终止时间转换成datatime数据类型，将剩余的类别型变量转换成数据型变量（[get_dummies](https://www.zhihu.com/search?q=get_dummies&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A106561665%7D)）

![](https://pic3.zhimg.com/80/v2-bb5729050fb326b67f6136dfe5e18de2_1440w.jpg)到这里数据清理完毕。

**步骤二：数据标准化**

找出合适的[特征变量](https://www.zhihu.com/search?q=%E7%89%B9%E5%BE%81%E5%8F%98%E9%87%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A106561665%7D)存入X中，并将数据进行标准化。

起始终止时间之差可以得到‘timeduration’,birthyear和age对应关系取其一，usertype和gender是各一对，取其一。得到如下特征变量。

![](https://pic4.zhimg.com/80/v2-94803643b73a7a35a1ab1bf971ce7e0f_1440w.jpg)查看相关性，发现timeduration和tripduration强相关（0.93），选其一。

![](https://pic2.zhimg.com/80/v2-3e0a83641ad6079247a445800c35db2d_1440w.png)将数据存入X，并进行数据标准化。

**步骤三：建立[聚类模型](https://www.zhihu.com/search?q=%E8%81%9A%E7%B1%BB%E6%A8%A1%E5%9E%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A106561665%7D)**

1.尝试不同分类的模型拟合

2.分析单变量维度的分群结果

3.使用[轮廓系数](https://www.zhihu.com/search?q=%E8%BD%AE%E5%BB%93%E7%B3%BB%E6%95%B0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A106561665%7D)评估模型效果

4.优化模型

![](https://pic2.zhimg.com/80/v2-d7209fdce4330a6b9f7cccfe97a00469_1440w.jpg)![](https://pic3.zhimg.com/80/v2-91d3b861cbde31accbab9c84047562f2_1440w.jpg)先尝试分为3类

对‘[gender_male](https://www.zhihu.com/search?q=gender_male&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A106561665%7D)’和'usertype_Subscriber'进行可视化（X,Y都挑0,1变量，比较好观察），理论上有4种结合可能，可视化的结果也很明显得展现了3种类别，分在4个角，说明这两个是比较好的特征变量。

第0组类型是customer,性别都有；

第1组类型是Subscriber,性别为男；

第2组类型是Subscriber，性别为女；

![](https://pic4.zhimg.com/80/v2-9e576e3f79e0bdd633668c552e8a2cdb_1440w.jpg)groupby同样可以得出一样的结果

![](https://pic1.zhimg.com/80/v2-421e3a1fa3301690e6daf3c99c3eb2dc_1440w.jpg)当聚类个数为3个时，评估模型的效果，轮廓系数为0.47**(评分越高，个体与群的距离越近，模型效果越好)**

利用“肘”方法找出最佳聚类个数

![](https://pic3.zhimg.com/80/v2-160d18e31f66fea5759cbde63a1dddc6_1440w.jpg) **快速下降趋于平缓下降的转折点是聚类最好的情况** ，图中为5时。

**步骤四：导出聚类结果，做出业务解读**

![](https://pic4.zhimg.com/80/v2-ef8ecb3ffff10dc7d3e7dd34b50d4cbf_1440w.jpg)查看5中分群的各自占比，1群最多，012群都是有相当数量的群体，34群只占很小一部分。

![](https://pic3.zhimg.com/80/v2-75cb1111d04457a76140abbc8c2d9ff6_1440w.jpg)可以查看一下导出的EXCEL中的内容，如上图

第一列是群组，重点关注每一列的数据，找出[绝对值](https://www.zhihu.com/search?q=%E7%BB%9D%E5%AF%B9%E5%80%BC&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A106561665%7D)最大的数，如果人群在某个特征变量上数据的绝对值比较大，就说明这个人群在这个特征上有较明显的区分度。

0群是较年长的用户，占比18.7%

1群是男性，会员，年轻，骑行时间短的用户，占比48.3%，是摩拜的核心用户群

2群是女性用户，占比19.8%

3群是非订阅用户，占比3.5%

4群是骑行时间较长的用户，占比9.8%

业务建议：

优先满足核心用户群，1群，猜测该类人群广泛分布于校园，或者刚出校园的年轻工作者，可以在校园中推广骑行活动，通过该群体人数规模大的优势进行品牌宣传扩大品牌影响力

# Python聚类分析-摩拜用户群分类

提到数据分析方法，可以分为三大类：回归分析、分类分析、聚类分析：

**回归分析** ：训练出已知的两个不同的数组间的函数关系，并作出预测；

**分类分析** ：从一组样本中，找出方法作出分类，并对未知参与训练的个体作出预测；

**聚类分析：** 对一组样本作出区分，成为探索几个簇间差异的依据。

今天要分享的是聚类分析，分析摩拜用户的分类，数据源取自知乎友的网盘数据，有需要可以私信我。

聚类分析的特点：

1、是一种无监督的学习算法，没有严格意义的对错之分；

2、不同的人或者方法，聚类的结果可能不一样；

3、对噪点敏感，需要提出噪点；

4、数据形状大都是不规则的球形，分类算法需要能处理特殊形状

5、聚类分析的是数据之间的距离远近。

**在分析之前，以下的数据都要经过标准化处理，即：**

![](https://pic3.zhimg.com/80/v2-0a0cb88ce3993ec43aa1c75ce1d5651a_1440w.jpg)
均值和方差在Excel中能计算得出

---

数据主要字段如下：

![](https://pic4.zhimg.com/80/v2-e3179b8423f631c2dbf096d23ec753bf_1440w.jpg)
数据字段列表

**一、数据清洗**

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
mobike_user=pd.read_csv('mobike.csv')
mobike_user.info()

```

![](https://pic2.zhimg.com/80/v2-9a75038f6770d24690fa34ae2161f0dd_1440w.jpg)**1、剔除聚类分析用不到的字段**

A、unique()查询有多少个起始站，发现有许多个，而且不规律，暂时不计入影响因素，删除，以此类推[终点站](https://www.zhihu.com/search?q=%E7%BB%88%E7%82%B9%E7%AB%99&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A121084140%7D)也删除。

![](https://pic1.zhimg.com/80/v2-5bdef600b66bf00e2c1ace6871e4a290_1440w.jpg)
开始站名字不唯一，删除

B、继续删除不需要的字段：

```text
mobike_user.drop(['user_id','bikeid','from_station_id','from_station_name','to_station_id','to_station_name'],axis=1,inplace=True)
```

整理完后发现还有一列：‘Unnamed:0’，也就是第一列，未命名的，可能是序号之类的，也删除，整理后最终的表格如下：

![](https://pic4.zhimg.com/80/v2-af7b3706b98c5f64e5d43b4cf1f1faf7_1440w.jpg)2、删除空值：

整理下看看有空值的占比，占比不大，可以删除：

```text
mobike_user.isnull().sum()/len(mobike_user)
```

![](https://pic1.zhimg.com/80/v2-29e697dd5f2e63c5d64181875a4837d4_1440w.jpg)

```text
mobike_user.dropna(inplace=True)
mobike_user.isnull().any()
```

![](https://pic4.zhimg.com/80/v2-4d3630368bd4854510efeb6286d0f95b_1440w.jpg)
剔除空值

3、删除异常值，如年龄为90-120岁之间的数据为异常

整体做描述统计分析：

![](https://pic1.zhimg.com/80/v2-d5434cef228506658e7181bfc1febae4_1440w.jpg)
发现仅有两个字段做了描述性统计

看下整体字段的类型

![](https://pic3.zhimg.com/80/v2-572c5be11369c483e82cd01ff7381052_1440w.jpg)tripduration为千位符格式，转为float类型，

```python3
mobike_user.tripduration=pd.to_numeric(mobike_user.tripduration.apply(lambda x:x.replace(",","")))
mobike_user.tripduration.describe()
```

![](https://pic2.zhimg.com/80/v2-e035aff8e8529a64a96589d5da2b9bd1_1440w.jpg)
tripduration修改字段类型为float

![](https://pic4.zhimg.com/80/v2-26b0b40bcec132b18462bbb725c30493_1440w.jpg)
age类型也直接转

修改字段类型后发现：

tripduration：有极值233732；age：有异常值101，

一般最大值比75%位数大三四倍就是异常值，调整数据，其中tripduration小于4000米，age小于70岁：

![](https://pic2.zhimg.com/80/v2-b7ae52dd1e722ef7dfa872208836bd39_1440w.jpg)
调整年龄小于70岁

![](https://pic1.zhimg.com/80/v2-145b5a6cee5d00615525bb8a16a78d88_1440w.jpg)
调整tripduration小于4000米

**剔除异常值结束后，开始完善字段格式** ，将起始终止时间转换成datatime数据类型，将剩余的类别型变量转换成[数据型变量](https://www.zhihu.com/search?q=%E6%95%B0%E6%8D%AE%E5%9E%8B%E5%8F%98%E9%87%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A121084140%7D)（get_dummies）

```text
mobike_user.start_time=pd.to_datetime(mobike_user.start_time)
mobike_user.end_time=pd.to_datetime(mobike_user.end_time)
mobike_user=pd.get_dummies(mobike_user)
mobike_user.head()
```

![](https://pic2.zhimg.com/80/v2-b79041950116605ceb7d7f9ff0fdd631_1440w.jpg)**二、数据标准化**

整理后发现birthyear和age数据关系重复；usertype和gender数据关系重复，各取其中一个变量来分析，找出合适的[特征变量](https://www.zhihu.com/search?q=%E7%89%B9%E5%BE%81%E5%8F%98%E9%87%8F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A121084140%7D)存入X中，并将数据进行标准化。

```text
mobike_user[['age','timeduration','tripduration','usertype_Customer','gender_Female']].corr()
```

![](https://pic4.zhimg.com/80/v2-9bc7406cefd609d9d060a269090b440b_1440w.jpg)
corr为分析相关性

发现'timeduration','tripduration'，两者高度正相关，取其中一个。

```text
x=mobike_user[['age','tripduration','usertype_Customer','gender_Female']]
from sklearn.preprocessing import scale
x=pd.DataFrame(scale(x))---scale为标准化数据语句
```

**三、建立模型**

1.不同分类模型的拟合

2.分析单变量维度的分群结果

3.使用轮廓系数评估模型效果

4.优化模型

![](https://pic1.zhimg.com/80/v2-7414f5fb274f63fa60ee0e6d90b8438c_1440w.jpg)![](https://pic1.zhimg.com/80/v2-ab9fa7573bd75671c33e9d67d68f1f50_1440w.jpg)
先尝试分为3类

对‘[gender_male](https://www.zhihu.com/search?q=gender_male&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A121084140%7D)’和'usertype_Subscriber'进行可视化，两个变量的字段都是0或1，比较好观察处理结果，可视化的结果也很明显得展现了3种类别，分在4个角，说明这两个是比较好的特征变量。

第0组类型是customer,性别都有；第1组类型是Subscriber,性别为男；第2组类型是Subscriber，性别为女；

![](https://pic4.zhimg.com/80/v2-34e6075afec25044df865e14af5ca37f_1440w.jpg)接下来尝试聚类的个数，其中，先从3个开始：

```text
from sklearn import metrics
x_cluster=model.fit_predict(x)
score=metrics.silhouette_score(x,x_cluster)
print('聚类个数为3时，轮廓函数：',score)
```

![](https://pic1.zhimg.com/80/v2-39c936f79e3c16398108e97b539cf75c_1440w.jpg)
轮廓系数越高说明聚类效果越好

为了找到最佳的聚类个数，利用“肘”方法找出最佳聚类个数：

> 肘部法则的计算原理是[成本函数](https://www.zhihu.com/search?q=%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A121084140%7D)，成本函数是类别畸变程度之和，
> 每个类的畸变程度等于每个变量点到其类别中心的位置距离[平方和](https://www.zhihu.com/search?q=%E5%B9%B3%E6%96%B9%E5%92%8C&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A121084140%7D)，若类内部的成员彼此间越紧凑则类的畸变程度越小，反之，若类内部的成员彼此间越分散则类的畸变程度越大。在选择类别数量上， **肘部法则会把不同值的成本函数值画出来** 。**随着值的增大，平均畸变程度会减小；每个类包含的样本数会减少，于是样本离其重心会更近。但是，随着值继续增大，平均畸变程度的改善效果会不断减低。值增大过程中，畸变程度的改善效果下降幅度最大的位置对应的值就是肘部。**
> 作者：enhengz
> 链接：[https://www.**jianshu.com/p/6dc5098bb**a1f](https://link.zhihu.com/?target=https%3A//www.jianshu.com/p/6dc5098bba1f)
> 来源：[简书](https://www.zhihu.com/search?q=%E7%AE%80%E4%B9%A6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A121084140%7D)

![](https://pic1.zhimg.com/80/v2-23202811e3e65e4e51ba1a9489c05f00_1440w.jpg)
可以发现数量5为肘部

**四、分析结果**

![](https://pic4.zhimg.com/80/v2-abd96d1f689bdae0f3a6013da6d9f01b_1440w.jpg)可以发现结果，2和3类客户群占到77%，1类客户群较少，

0组用户：年龄较大，男性，占比18.74%；

1组用户：男性用户，非会员，占比3%；

2组用户：女性较年轻会员，占比19.96%；

3组用户：男性较年轻会员，骑行时间正常，占比48.4%；

4组用户：骑行时间较长的用户，占比9.79%。

**结论：** 针对3组用户，即年轻男性做不定时推广，如校园套餐、软件园附近套餐或推广；2组用户使用频率不高，相较于3组用户时长较久，为远距离骑行，可以按周来发送优惠券。

**以上学习内容参考知友的内容，学习Python的语法和聚类分析过程。**

[艾伦：python聚类分析-摩拜单车用户分群**65 赞同 · 16 评论**文章![](https://pic1.zhimg.com/v2-3a373e45533f1e243a5f784d139e7728_180x120.jpg)](https://zhuanlan.zhihu.com/p/106561665)
